{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-03T10:47:49.122236600Z",
     "start_time": "2023-10-03T10:47:30.093858200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "max_prediction_length = 2*24 #the goal is to make a one-day forecast 48\n",
    "max_encoder_length = 7*2*24\n",
    "group = 0 # a week 336\n",
    "test_sequence = pd.read_csv('tankleak.csv')\n",
    "test_sequence = test_sequence.drop(columns=[\"Month\", \"Year\", \"Season\"])\n",
    "test_sequence['period'] = test_sequence['period'].astype(str)\n",
    "TRAINSIZE = 2000\n",
    "VALIDSIZE = 500\n",
    "data = test_sequence[lambda x: x.time_idx <= TRAINSIZE+VALIDSIZE]\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    test_sequence[lambda x: x.time_idx <= TRAINSIZE],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Var_tc_readjusted\", #variance\n",
    "    group_ids=[\"group_id\"], #tank id\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"group_id\"], #tank id, tank location state\n",
    "    static_reals=[\"tank_max_height\", \"tank_max_volume\"], #tank max height, tank max volume, no. of pumps attached to the tank\n",
    "    time_varying_known_categoricals=[\"Time_of_day\"], #season, month, remove \"Month\", \"Year\", \"Season\" if use only a month of data for training\n",
    "    time_varying_known_reals=[\"time_idx\"], #time_idx,\n",
    "    time_varying_unknown_categoricals=[\"period\"],  #  period (idle, transaction, delivery)\n",
    "    time_varying_unknown_reals=[\n",
    "        \"Var_tc_readjusted\",\n",
    "        \"Del_tc\",\n",
    "        \"Sales_Ini_tc\",\n",
    "        \"ClosingHeight_tc_readjusted\",\n",
    "        \"ClosingStock_tc_readjusted\",\n",
    "        \"TankTemp\",\n",
    "    ], # variance, volume, height, sales(-), delivery(+), temperature,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T10:51:24.806381500Z",
     "start_time": "2023-10-03T10:49:35.188789900Z"
    }
   },
   "id": "5f7903e16791ea8f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:51:40,452] A new study created in memory with name: no-name-c2ede968-bb73-43e0-ac0c-9a8a8a408bc0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-10-03 23:16:45,138] Trial 0 finished with value: 2.842017650604248 and parameters: {'gradient_clip_val': 0.3595375095813248, 'hidden_size': 14, 'dropout': 0.28519335459069856, 'hidden_continuous_size': 9, 'attention_head_size': 2, 'learning_rate': 0.03601119460172352}. Best is trial 0 with value: 2.842017650604248.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-10-04 00:48:14,681] Trial 1 finished with value: 2.804687738418579 and parameters: {'gradient_clip_val': 0.03571663686788617, 'hidden_size': 15, 'dropout': 0.17085966100984748, 'hidden_continuous_size': 8, 'attention_head_size': 2, 'learning_rate': 0.04044358859683056}. Best is trial 1 with value: 2.804687738418579.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-10-04 02:07:57,975] Trial 2 finished with value: 2.9125216007232666 and parameters: {'gradient_clip_val': 0.08320810211416046, 'hidden_size': 12, 'dropout': 0.2790261881321414, 'hidden_continuous_size': 10, 'attention_head_size': 3, 'learning_rate': 0.016870626426198167}. Best is trial 1 with value: 2.804687738418579.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-10-04 05:15:54,677] Trial 3 finished with value: 2.9333410263061523 and parameters: {'gradient_clip_val': 0.07689146489772632, 'hidden_size': 38, 'dropout': 0.2544173814290006, 'hidden_continuous_size': 25, 'attention_head_size': 3, 'learning_rate': 0.0018860535197992411}. Best is trial 1 with value: 2.804687738418579.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-10-04 09:41:46,042] Trial 4 finished with value: 2.8121397495269775 and parameters: {'gradient_clip_val': 0.03971722345723291, 'hidden_size': 57, 'dropout': 0.15599651537166676, 'hidden_continuous_size': 25, 'attention_head_size': 4, 'learning_rate': 0.04278537589070402}. Best is trial 1 with value: 2.804687738418579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_clip_val': 0.03571663686788617, 'hidden_size': 15, 'dropout': 0.17085966100984748, 'hidden_continuous_size': 8, 'attention_head_size': 2, 'learning_rate': 0.04044358859683056}\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=20,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T22:41:46.080933100Z",
     "start_time": "2023-10-03T10:51:40.449332900Z"
    }
   },
   "id": "73728dc5d77ac844"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6d04dcf887f0b9a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
